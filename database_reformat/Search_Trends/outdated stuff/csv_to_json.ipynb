{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to JSON Converter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-36e1091516ce>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-36e1091516ce>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    key = rows[]\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def make_json(csvFilePath, jsonFilePath):   \n",
    "    # create a dictionary \n",
    "    data = {} \n",
    "    key = ['Vertices', 'Edges']\n",
    "    data[key] = [rows, 0]\n",
    "      \n",
    "    # Open a csv reader called DictReader \n",
    "    with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "        csvReader = csv.DictReader(csvf) \n",
    "          \n",
    "        # Convert each row into a dictionary  \n",
    "        # and add it to data \n",
    "        for rows in csvReader: \n",
    "\n",
    "            key = rows \n",
    "            data[key] = rows \n",
    "  \n",
    "    # Open a json writer, and use the json.dumps()  \n",
    "    # function to dump data \n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n",
    "        jsonf.write(json.dumps(data, indent=4)) \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver Code \n",
    "  \n",
    "# Decide the two file paths according to your  \n",
    "# computer system \n",
    "csvFilePath = r'exampledata.csv'\n",
    "jsonFilePath = r'exampledata.json'\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2c01f27a217b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Call the make_json function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmake_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-6868b3dd4ed2>\u001b[0m in \u001b[0;36mmake_json\u001b[0;34m(csvFilePath, jsonFilePath)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Vertices'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Edges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Open a csv reader called DictReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rows' is not defined"
     ]
    }
   ],
   "source": [
    "# Call the make_json function \n",
    "make_json(csvFilePath, jsonFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Trends Dataframe to JSON Converter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas import DataFrame\n",
    "from pytrends.request import TrendReq\n",
    "import numpy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Google. Only need to run this once, the rest of requests will use the same session.\n",
    "pytrend = TrendReq(hl='en-US', tz=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of search terms\n",
    "keyword = (['coronavirus'])\n",
    "location = ('US-CA')\n",
    "timeframe = ('2020-04-01 2020-04-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from Google Trends:\n",
    "\n",
    "# Create payload and capture API tokens. Only needed for \n",
    "# interest_over_time(), interest_by_region() & related_queries()\n",
    "pytrend.build_payload(keyword, cat=0, timeframe=timeframe,geo=location,gprop='')\n",
    "\n",
    "# Create dataframe of interest over time\n",
    "df = pytrend.interest_over_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Search Popularity</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>75</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>74</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>95</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>99</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>100</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>97</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-04-07</td>\n",
       "      <td>94</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-04-08</td>\n",
       "      <td>88</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-04-09</td>\n",
       "      <td>81</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-04-10</td>\n",
       "      <td>80</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>62</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>50</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-04-13</td>\n",
       "      <td>72</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-04-14</td>\n",
       "      <td>76</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-04-15</td>\n",
       "      <td>71</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>67</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>71</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-04-18</td>\n",
       "      <td>74</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>51</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>60</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>66</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>45</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>58</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>62</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-04-25</td>\n",
       "      <td>44</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-04-26</td>\n",
       "      <td>35</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-04-27</td>\n",
       "      <td>34</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>33</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>30</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>29</td>\n",
       "      <td>US-CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Search Popularity Location\n",
       "0  2020-04-01                 75    US-CA\n",
       "1  2020-04-02                 74    US-CA\n",
       "2  2020-04-03                 95    US-CA\n",
       "3  2020-04-04                 99    US-CA\n",
       "4  2020-04-05                100    US-CA\n",
       "5  2020-04-06                 97    US-CA\n",
       "6  2020-04-07                 94    US-CA\n",
       "7  2020-04-08                 88    US-CA\n",
       "8  2020-04-09                 81    US-CA\n",
       "9  2020-04-10                 80    US-CA\n",
       "10 2020-04-11                 62    US-CA\n",
       "11 2020-04-12                 50    US-CA\n",
       "12 2020-04-13                 72    US-CA\n",
       "13 2020-04-14                 76    US-CA\n",
       "14 2020-04-15                 71    US-CA\n",
       "15 2020-04-16                 67    US-CA\n",
       "16 2020-04-17                 71    US-CA\n",
       "17 2020-04-18                 74    US-CA\n",
       "18 2020-04-19                 51    US-CA\n",
       "19 2020-04-20                 60    US-CA\n",
       "20 2020-04-21                 66    US-CA\n",
       "21 2020-04-22                 45    US-CA\n",
       "22 2020-04-23                 58    US-CA\n",
       "23 2020-04-24                 62    US-CA\n",
       "24 2020-04-25                 44    US-CA\n",
       "25 2020-04-26                 35    US-CA\n",
       "26 2020-04-27                 34    US-CA\n",
       "27 2020-04-28                 33    US-CA\n",
       "28 2020-04-29                 30    US-CA\n",
       "29 2020-04-30                 29    US-CA"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatting dataframe:\n",
    "\n",
    "# move dates into a column\n",
    "df = df.reset_index()\n",
    "\n",
    "# change column names\n",
    "df.columns=['Date','Search Popularity','Trash']\n",
    "\n",
    "# get rid of useless information\n",
    "df = df[['Date','Search Popularity']]\n",
    "\n",
    "# add location column\n",
    "df['Location'] = location\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECTLY FROM DATAFRAME:\n",
    "\n",
    "import json\n",
    "from json import JSONEncoder\n",
    "import numpy\n",
    "\n",
    "# Currently having the issue of it cant put timestamps into the array\n",
    "# we ignore dates for now by limiting the information in the dataframe:\n",
    "\n",
    "df1 = df[['Search Popularity', 'Location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing JSON serialized NumPy array\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"Data_1\": {\"Vertices\": {\"0\": [75, \"US-CA\"], \"1\": [74, \"US-CA\"], \"2\": [95, \"US-CA\"], \"3\": [99, \"US-CA\"], \"4\": [100, \"US-CA\"], \"5\": [97, \"US-CA\"], \"6\": [94, \"US-CA\"], \"7\": [88, \"US-CA\"], \"8\": [81, \"US-CA\"], \"9\": [80, \"US-CA\"], \"10\": [62, \"US-CA\"], \"11\": [50, \"US-CA\"], \"12\": [72, \"US-CA\"], \"13\": [76, \"US-CA\"], \"14\": [71, \"US-CA\"], \"15\": [67, \"US-CA\"], \"16\": [71, \"US-CA\"], \"17\": [74, \"US-CA\"], \"18\": [51, \"US-CA\"], \"19\": [60, \"US-CA\"], \"20\": [66, \"US-CA\"], \"21\": [45, \"US-CA\"], \"22\": [58, \"US-CA\"], \"23\": [62, \"US-CA\"], \"24\": [44, \"US-CA\"], \"25\": [35, \"US-CA\"], \"26\": [34, \"US-CA\"], \"27\": [33, \"US-CA\"], \"28\": [30, \"US-CA\"], \"29\": [29, \"US-CA\"]}}}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to serialize the array into a json string. \n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):      #checks to make sure it is an array\n",
    "            output={}\n",
    "            vertex_list = obj.tolist()\n",
    "            output['Vertices'] = dict(zip(range(len(vertex_list)), vertex_list)) \n",
    "            return output\n",
    "        return JSONEncoder.default(self, obj)\n",
    "    \n",
    "numpyArray = numpy.array(df1)\n",
    "\n",
    "numpyData = {\"Data_1\": numpyArray}\n",
    "jsondata = json.dumps(numpyData, cls=NumpyArrayEncoder)  # use dump() to write array into file\n",
    "print(\"Printing JSON serialized NumPy array\")\n",
    "\n",
    "jsondata\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
